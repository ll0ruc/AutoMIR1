{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproduction process of training generator and retriever",
   "id": "51ec8466eb9986f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.0 Generate query from courpus",
   "id": "38a6d8ba6d2358f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!cd ./src\n",
    "!python gen_Data.gen_Query_data.py --corpus_path \"./train_data/corpus.jsonl\" --llm_name Qwen-32b"
   ],
   "id": "12ee975c0b47ac7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### You will get the query.jsonl file in the train_data folder, which contains the generated queries for each document in the corpus.",
   "id": "f576b95899594782"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Generate training data for LLM",
   "id": "86d1231f08ee391a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!python gen_Data.gen_LLM_data.py --query_path \"./train_data/query.jsonl\" --llm_name_gen_llm qwen",
   "id": "dd2c60e8bd79e312"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### You will get the llm_train_data.jsonl file in the train_data/qwen folder, which contains the generated training data for LLM.",
   "id": "41c972923f86f613"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Fine-tuning LLM as Generator",
   "id": "2a1dec729b8aa8f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!bash run train_llm.sh",
   "id": "d1ee56e1e044337a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### You will get the fine-tuned LLM model in the outputs/qwen folder, which can be used as a generator for generating retwriten queries.",
   "id": "527eece0d9c018c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Generate training data for Retriever",
   "id": "4a34d03b4395a6f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!python gen_Data.gen_EMB_data.py --llm_name qwen",
   "id": "1715acd2d542867"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### You will get the emb_train_data.jsonl file in the train_data/qwen folder, which contains the generated training data for retriever.",
   "id": "654115d71aa0d792"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Fine-tuning Retriever",
   "id": "e70e6afda21add2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!bash run train_emb.sh",
   "id": "ac84264b8b281fe9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### You will get the fine-tuned retriever model in the outputs/qwen folder, which can be used for retrieving relevant documents based on the generated queries.",
   "id": "f84f9d02c0aeca4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3 Evaluating Retriever",
   "id": "ba04e522e664eb6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!python evaluate.py --retrieval_name bge-FT --llm_name qwen",
   "id": "276c27bc32849d83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### You will get the evaluation results in the results/ folder, which contains the evaluation metrics for the retriever model.",
   "id": "c4f1911a1598b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
